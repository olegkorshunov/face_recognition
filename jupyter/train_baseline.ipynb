{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/e/projects/face_recognition\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import albumentations as A\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.models import efficientnet_v2_s\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from config import CFG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Число уникальных людей 10174, каждый человек имеет, как минимум 28 фоток.\n",
      "Всего фоток 59959\n",
      "df(59959) -> train(43767) val(8096) test(8096)\n"
     ]
    }
   ],
   "source": [
    "def get_dataset_and_filter_by_label_trashold(label_trashold: int = 10):\n",
    "    \"\"\"\n",
    "    удалим из датасета, тех людей, у которых мало фото - label_trashold.\n",
    "    Увеличивая label_trashold, мы умешьнаем размер датасета.\n",
    "\n",
    "    \"\"\"\n",
    "    df_identity = pd.read_csv(CFG.identity_path, sep=\" \", header=None).sort_values(by=0).reset_index(drop=True)\n",
    "    df_identity.columns = [\"image\", \"label\"]\n",
    "    cropped_imgs = os.listdir(CFG.img_folder_dst)\n",
    "    data = pd.DataFrame({\"image\": cropped_imgs})\n",
    "    data = data.join(df_identity.set_index(\"image\"), on=\"image\", how=\"left\")\n",
    "    data_tmp = data.groupby([\"label\"]).agg({\"label\": \"count\"}).rename(columns={\"label\": \"label_count\"})\n",
    "    print(f\"Число уникальных людей {len(data_tmp)}, каждый человек имеет, как минимум {label_trashold} фоток.\")\n",
    "\n",
    "    del_label = data_tmp.loc[data_tmp.label_count <= label_trashold, :].index.values\n",
    "    mask = data[\"label\"].isin(set(del_label))\n",
    "    data = data[~mask].reset_index(drop=True)\n",
    "    print(f\"Всего фоток {len(data)}\")\n",
    "    df_labels = data[\"label\"].unique()\n",
    "    map_lables = {l: i for i, l in enumerate(df_labels)}\n",
    "    data[\"label\"] = data[\"label\"].map(lambda x: map_lables[x])\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def split_dataset_by_photo(df, label_col, num_val_samples_per_class):\n",
    "    validation_data = []\n",
    "    train_data = []\n",
    "    test_data = []\n",
    "\n",
    "    for label in df[label_col].unique():\n",
    "        label_data = df[df[label_col] == label]\n",
    "\n",
    "        val_samples = label_data.sample(num_val_samples_per_class)\n",
    "        validation_data.append(val_samples)\n",
    "        label_data = label_data.drop(val_samples.index)\n",
    "\n",
    "        test_samples = label_data.sample(num_val_samples_per_class)\n",
    "        test_data.append(test_samples)\n",
    "        label_data = label_data.drop(test_samples.index)\n",
    "\n",
    "        train_data.append(label_data)\n",
    "\n",
    "    train_df = pd.concat(train_data).reset_index(drop=True)\n",
    "    validation_df = pd.concat(validation_data).reset_index(drop=True)\n",
    "    test_df = pd.concat(test_data).reset_index(drop=True)\n",
    "    print(f\"df({len(df)}) -> train({len(train_df)}) val({len(validation_df)}) test({len(test_df)})\")\n",
    "\n",
    "    return train_df, validation_df, test_df\n",
    "\n",
    "\n",
    "# Split the dataset\n",
    "\n",
    "# df_train, df_val, df_test = split_by_person()\n",
    "df_train, df_val, df_test = split_dataset_by_photo(\n",
    "    get_dataset_and_filter_by_label_trashold(CFG.label_trashold),\n",
    "    \"label\",\n",
    "    4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CelebaDataet(Dataset):\n",
    "    def __init__(self, df: pd.DataFrame) -> None:\n",
    "        # image, label\n",
    "        self.df = df.values\n",
    "        self.transform = A.Compose(\n",
    "            [\n",
    "                # A.Resize(height=128, width=128),\n",
    "                A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "                ToTensorV2(),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_path, label = self.df[index]\n",
    "        img = cv2.imread(os.path.join(CFG.img_folder_dst, img_path))\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = self.transform(image=img)[\"image\"]\n",
    "        return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CelebaDataet(df_train)\n",
    "val_dataset = CelebaDataet(df_val)\n",
    "test_dataset = CelebaDataet(df_test)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=26, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=26, shuffle=False)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=26, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2024"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_amount = len(df_train[\"label\"].unique())\n",
    "labels_amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = efficientnet_v2_s()\n",
    "model.load_state_dict(torch.load(\"models/efficientnet_v2_s.pth\"))\n",
    "model.classifier = nn.Sequential(nn.Dropout(p=0.2), nn.Linear(in_features=1280, out_features=labels_amount))\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "def train(model, train_loader, val_loader, opt, epochs=10):\n",
    "    train_losses, val_losses, val_full_acc, train_full_acc = [], [], [], []\n",
    "    best_acc = 0.0\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    best_model_weights = deepcopy(model.state_dict())\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"========= Epoch {epoch + 1} / {epochs} =========\")\n",
    "\n",
    "        # TRAIN\n",
    "        model.train()\n",
    "        current_train_loss = 0\n",
    "        current_train_correct = 0\n",
    "\n",
    "        for inputs, labels in tqdm(train_loader):\n",
    "            X_batch = inputs.to(device)\n",
    "            Y_batch = labels.to(device)\n",
    "\n",
    "            opt.zero_grad()\n",
    "\n",
    "            # forward\n",
    "            Y_pred = model(X_batch)\n",
    "            preds = torch.argmax(Y_pred, 1)\n",
    "            loss = loss_fn(Y_pred, Y_batch)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "            current_train_loss += loss.item() * X_batch.size(0)\n",
    "            current_train_correct += torch.sum(preds == Y_batch)\n",
    "\n",
    "        opt.step()\n",
    "\n",
    "        train_loss = current_train_loss / len(train_dataset)\n",
    "        train_losses.append(train_loss)\n",
    "        train_acc = current_train_correct / len(train_dataset)\n",
    "        train_full_acc.append(train_acc)\n",
    "        print(\"train loss =\", train_loss)\n",
    "        print(\"train acc = {:.2f}%\".format(train_acc.item() * 100))\n",
    "\n",
    "        # VALIDATION\n",
    "        model.eval()\n",
    "        current_val_loss = 0\n",
    "        current_val_correct = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                X_val = inputs.to(device)\n",
    "                Y_val = labels.to(device)\n",
    "\n",
    "                outputs = model(X_val)\n",
    "                val_loss = loss_fn(outputs, Y_val)\n",
    "                preds = torch.argmax(outputs, 1)\n",
    "                current_val_correct += torch.sum(preds == Y_val)\n",
    "                current_val_loss += val_loss.item() * X_val.size(0)\n",
    "\n",
    "        val_acc = current_val_correct / len(val_dataset)\n",
    "        val_loss = current_val_loss / len(val_dataset)\n",
    "\n",
    "        print(\"val loss =\", val_loss)\n",
    "        print(f\"val acc = {val_acc.item() * 100:.2f}%\")\n",
    "        val_losses.append(val_loss)\n",
    "        val_full_acc.append(val_acc)\n",
    "\n",
    "        if val_acc > best_acc:\n",
    "            best_acc = val_acc\n",
    "            best_model_weights = deepcopy(model.state_dict())\n",
    "            print(\"Save new model!\")\n",
    "\n",
    "    return best_model_weights, train_losses, val_losses, val_full_acc, train_full_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= Epoch 1 / 10 =========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1684/1684 [15:07<00:00,  1.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss = 7.0746523576594775\n",
      "train acc = 0.78%\n",
      "val loss = 6.094135032340943\n",
      "val acc = 2.67%\n",
      "Save new model!\n",
      "========= Epoch 2 / 10 =========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1684/1684 [14:58<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss = 4.983188976686857\n",
      "train acc = 11.32%\n",
      "val loss = 4.228897669687573\n",
      "val acc = 19.37%\n",
      "Save new model!\n",
      "========= Epoch 3 / 10 =========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1684/1684 [15:02<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss = 2.8756535039117037\n",
      "train acc = 40.55%\n",
      "val loss = 2.5614408982453845\n",
      "val acc = 47.84%\n",
      "Save new model!\n",
      "========= Epoch 4 / 10 =========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1684/1684 [15:08<00:00,  1.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss = 1.6184822025795227\n",
      "train acc = 64.56%\n",
      "val loss = 1.7158942607787286\n",
      "val acc = 64.71%\n",
      "Save new model!\n",
      "========= Epoch 5 / 10 =========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1684/1684 [14:45<00:00,  1.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss = 1.0258965397122426\n",
      "train acc = 76.92%\n",
      "val loss = 1.4740620413611059\n",
      "val acc = 69.76%\n",
      "Save new model!\n",
      "========= Epoch 6 / 10 =========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1684/1684 [14:48<00:00,  1.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss = 0.6998283730640098\n",
      "train acc = 84.09%\n",
      "val loss = 1.3757828170647146\n",
      "val acc = 71.69%\n",
      "Save new model!\n",
      "========= Epoch 7 / 10 =========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1684/1684 [14:27<00:00,  1.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss = 0.5111327222473842\n",
      "train acc = 88.11%\n",
      "val loss = 1.2035483741587978\n",
      "val acc = 76.26%\n",
      "Save new model!\n",
      "========= Epoch 8 / 10 =========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1684/1684 [12:37<00:00,  2.22it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss = 0.37747268182873195\n",
      "train acc = 90.98%\n",
      "val loss = 1.1824011374356984\n",
      "val acc = 76.47%\n",
      "Save new model!\n",
      "========= Epoch 9 / 10 =========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1684/1684 [11:21<00:00,  2.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss = 0.2922997477205177\n",
      "train acc = 92.99%\n",
      "val loss = 1.151382854988747\n",
      "val acc = 78.48%\n",
      "Save new model!\n",
      "========= Epoch 10 / 10 =========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1684/1684 [12:53<00:00,  2.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss = 0.24257110494495618\n",
      "train acc = 93.98%\n",
      "val loss = 1.1887537687059802\n",
      "val acc = 77.17%\n"
     ]
    }
   ],
   "source": [
    "model.to(device)\n",
    "\n",
    "opt = torch.optim.AdamW(model.parameters())\n",
    "best_model_weights, train_losses, val_losses, val_full_acc, train_full_acc = train(\n",
    "    model, train_dataloader, val_dataloader, opt, epochs=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(best_model_weights, \"models/efficientnet_v2_s_ce_10_epoch.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024\n"
     ]
    }
   ],
   "source": [
    "print(labels_amount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 312/312 [01:54<00:00,  2.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct answers: 6325 from 8096 \n",
      "Test accuracy = 78.13%\n"
     ]
    }
   ],
   "source": [
    "def test_result(model, test_loader):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        current_test_acc = 0\n",
    "        for inputs, labels in tqdm(test_loader):\n",
    "            X_test = inputs.to(device)\n",
    "            Y_test = labels.to(device)\n",
    "            outputs = model(X_test)\n",
    "            preds = torch.argmax(outputs, 1)\n",
    "            current_test_acc += torch.sum(Y_test == preds)\n",
    "    print(\"Correct answers: {} from {} \".format(current_test_acc, len(test_dataset)))\n",
    "    test_acc = current_test_acc / len(test_dataset)\n",
    "    print(\"Test accuracy = {:.2f}%\".format(test_acc * 100))\n",
    "\n",
    "\n",
    "best_model = efficientnet_v2_s()\n",
    "best_model.classifier = nn.Sequential(nn.Dropout(p=0.2), nn.Linear(in_features=1280, out_features=labels_amount))\n",
    "best_model.load_state_dict(best_model_weights)\n",
    "\n",
    "test_result(best_model.to(device), test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "main",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
